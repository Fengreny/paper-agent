# agent.py
import os
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser

from schema import AgentState
from tools.pdf_utils import read_pdf_with_pages
from tools.web_search import search_web

from dotenv import load_dotenv
load_dotenv()

# åˆå§‹åŒ– LLM
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)  # æˆ–è€…ä½ çš„ deepseek æ¨¡å‹


# ==========================================
# 1. Reader Node 
# ==========================================
def reader_node(state: AgentState):
    file_path = state["file_path"]

    # è¯»å– PDF (å¸¦é¡µç )
    pages = read_pdf_with_pages(file_path)

    # ä¸ºäº†è®© LLM æå–æ¦‚å¿µï¼Œæˆ‘ä»¬è¿˜æ˜¯éœ€è¦æ‹¼ä¸€ä¸ªå…¨æ–‡ï¼Œä½†è¿™æ¬¡åªæ˜¯ä¸ºäº†æå–æ¦‚å¿µ
    # çœŸæ­£çš„å¼•ç”¨åœ¨ Writer é˜¶æ®µåš
    full_text_for_summary = "\n".join([p["content"] for p in pages[:5]])  # åªè¯»å‰5é¡µåšæ‘˜è¦ï¼ŒèŠ‚çœ tokenï¼Œæˆ–è€…è¯»å…¨æ–‡

    # è®°å½•æ—¥å¿—
    logs = [f"âœ… æˆåŠŸè¯»å– PDFï¼Œå…± {len(pages)} é¡µã€‚"]

    # æå–æ ¸å¿ƒæ¦‚å¿µçš„ Prompt
    summary_prompt = ChatPromptTemplate.from_template(
        """
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ AI è®ºæ–‡é˜…è¯»åŠ©æ‰‹ã€‚
        è¯·é˜…è¯»ä»¥ä¸‹è®ºæ–‡ç‰‡æ®µï¼Œæå–å‡º 3-5 ä¸ªæœ€å…³é”®çš„æŠ€æœ¯æœ¯è¯­æˆ–æ ¸å¿ƒæ¦‚å¿µï¼ˆç‰¹åˆ«æ˜¯é‚£äº›å¯èƒ½éœ€è¦è”ç½‘æœç´¢æ‰èƒ½æ·±å…¥ç†è§£çš„ï¼‰ã€‚

        è¾“å‡ºæ ¼å¼å¿…é¡»æ˜¯ JSON:
        {{
            "summary": "ä¸€å¥è¯æ¦‚æ‹¬è®ºæ–‡ä¸»æ—¨",
            "key_concepts": ["æ¦‚å¿µ1", "æ¦‚å¿µ2", "æ¦‚å¿µ3"]
        }}

        è®ºæ–‡ç‰‡æ®µ:
        {text}
        """
    )

    chain = summary_prompt | llm | JsonOutputParser()
    result = chain.invoke({"text": full_text_for_summary})

    logs.append(f"ğŸ§  æå–åˆ°æ ¸å¿ƒæ¦‚å¿µ: {', '.join(result['key_concepts'])}")

    return {
        "pdf_pages": pages,
        "summary": result["summary"],
        "key_concepts": result["key_concepts"],
        "thought_log": logs
    }


# ==========================================
# 2. Researcher Node
# ==========================================
def researcher_node(state: AgentState):
    concepts = state["key_concepts"]
    search_results = {}
    logs = state.get("thought_log", [])

    logs.append("ğŸŒ å¼€å§‹è”ç½‘æœç´¢èƒŒæ™¯çŸ¥è¯†...")

    for concept in concepts:
        # ç®€å•æœç´¢
        query = f"{concept} explanation machine learning"
        result = search_web(query)
        search_results[concept] = result
        logs.append(f"   -> å·²æœç´¢ '{concept}'ï¼Œè·å–äº†ç›¸å…³èµ„æ–™ã€‚")

    return {
        "search_results": search_results,
        "thought_log": logs
    }


# ==========================================
# 3. Writer Node
# ==========================================


def writer_node(state: AgentState):
    pages = state["pdf_pages"]
    search_data = state["search_results"]
    summary = state["summary"]
    logs = state.get("thought_log", [])

    logs.append("âœï¸ æ­£åœ¨æ’°å†™æœ€ç»ˆæŠ¥å‘Š...")

    # æ„é€ ä¸Šä¸‹æ–‡
    context_with_pages = ""
    for p in pages:
        content_preview = p['content'][:2000]
        context_with_pages += f"\n=== Page {p['page_number']} ===\n{content_preview}\n"

    writer_prompt = ChatPromptTemplate.from_template(
        """
        ä½ æ˜¯ä¸€ä¸ªé«˜çº§ç®—æ³•å·¥ç¨‹å¸ˆä¸“å®¶ã€‚è¯·æ ¹æ®æä¾›çš„è®ºæ–‡å†…å®¹å’Œè”ç½‘æœç´¢è¡¥å……çš„çŸ¥è¯†ï¼Œæ’°å†™ä¸€ä»½æ·±åº¦æŠ€æœ¯æŠ¥å‘Šã€‚

        ã€è¾“å…¥ç´ æã€‘
        1. è®ºæ–‡å…¨æ–‡ï¼ˆå¸¦é¡µç æ ‡è®°ï¼‰ï¼š
        {context}

        2. è”ç½‘æœç´¢è¡¥å……çŸ¥è¯†ï¼ˆç”¨äºè§£é‡Šå¤æ‚æ¦‚å¿µï¼‰ï¼š
        {search_data}

        ã€å†™ä½œè¦æ±‚ã€‘
        1. **ç»“æ„åŒ–å›¾è¡¨**ï¼šå¼€å¤´åŒ…å« Mermaid æ€ç»´å¯¼å›¾ã€‚
        2. **ä¸¥æ ¼çš„æ¥æºåŒºåˆ†ï¼ˆå…³é”®ï¼‰**ï¼š
           - å‡¡æ˜¯å¼•ç”¨è®ºæ–‡åŸæ–‡çš„ï¼Œå¿…é¡»åœ¨å¥å°¾æ ‡æ³¨ `[Page X]`ã€‚
           - å‡¡æ˜¯å¼•ç”¨**è”ç½‘æœç´¢**è¡¥å……çš„å†…å®¹ï¼ˆå¦‚èƒŒæ™¯ä»‹ç»ã€å…¬å¼è§£é‡Šã€ç«å“å¯¹æ¯”ï¼‰ï¼Œå¿…é¡»ä½¿ç”¨å¼•ç”¨å—æ ¼å¼ï¼Œå¹¶æ ‡æ³¨ğŸŒå›¾æ ‡ã€‚

           æ ¼å¼ç¤ºä¾‹ï¼š
           DeepSeek-R1 é‡‡ç”¨äº† GRPO ç®—æ³• [Page 5]ã€‚
           > ğŸŒ **ç½‘ç»œè¡¥å…… / èƒŒæ™¯çŸ¥è¯†**ï¼š
           > GRPO (Group Relative Policy Optimization) æ˜¯ä¸€ç§ä¸éœ€è¦ä»·å€¼ç½‘ç»œï¼ˆValue Networkï¼‰çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œå®ƒé€šè¿‡...ï¼ˆæ­¤å¤„å†™æœç´¢åˆ°çš„è¡¥å……å†…å®¹ï¼‰ã€‚

        3. **ä»£ç å±•ç¤º**ï¼šå±•ç¤ºæ ¸å¿ƒç®—æ³•çš„ Python ä¼ªä»£ç ã€‚
        4. **æ·±åº¦è§£æ**ï¼šåˆ©ç”¨æœç´¢åˆ°çš„çŸ¥è¯†ï¼Œè§£é‡Šè®ºæ–‡ä¸­æœªè¯¦ç»†å±•å¼€çš„æœ¯è¯­ã€‚

        ã€è¾“å‡ºæ ¼å¼ã€‘
        Markdown æ ¼å¼ã€‚
        """
    )

    chain = writer_prompt | llm | StrOutputParser()
    report = chain.invoke({
        "context": context_with_pages,
        "search_data": str(search_data)
    })

    # è¿½åŠ æ—¥å¿—
    final_report = report
    if "Agent æ€è€ƒæ—¥å¿—" not in report:
        log_str = "\n\n## ğŸ•µï¸ Agent æ€è€ƒæ—¥å¿—\n" + "\n".join([f"- {log}" for log in logs])
        final_report += log_str

    return {
        "final_report": final_report,
        "thought_log": logs
    }

